# Concept and Application


Team Maturity Model (TMM) is a checklist divided into maturity levels that checks the most important provisions for us in the product, process, and engineering areas.


Every area has list of metrics and questions. The overall index of Maturity is the arithmetic mean from each subject area.


Each question is divided into 4 levels:


| Zero | First | Second | Third |
| --- | --- | --- | --- |
| Not relevant or unavailable | Partially relevant, some results | Relevant to the basic expectations of the company | Excellent level, higher than expected |
|  |  |  |  |


**The TMM questions are bases on the following principles**:


* The question raised is universal, and we want to see a high level of this practice in each of the teams (be it platform or product teams).
* Some question can be displayed through a metric on the dashboard. So they represent a breakdown of the metric into levels. Some questions are related to mastering the practice and are filled in only by the team. We assume that everyone is honest in their answer.
* The questions are formulated as unambiguously as possible and clear recommendations for improving the level can be written.
* The questions are formulated by the SMEs, product and technology division heads and the PMO team. 

<br>



# Purpose


We position TMM as a tool for inspecting and adapting processes within the team. With its help:


* we show the described target picture from the company's side, which is expressed in the second level, that is, we explicitly transmit expectations by maturity level;
* we motivate the team to self-reflection on the path of continuous improvement â€” a comprehensive assessment of themselves in comparison with the baseline and the formation of a backlog of improvements;
* we get material for prioritizing the collected points of improvement and creating a roadmap for each team;
* we set the vector for a new team or an idea for inspiration and a boost for the "old" teammates;
* it develops the culture that the team owns its processes and is responsible for them.

<br>



It is important to note separately what we do not use the tool for:


* the received level is not a reason for punishment or rewards and not material for comparison;
* the third level not received does not mean that the team is doing poorly. We leave it to the participants to figure out for themselves which points are a priority for their context. Team members know better where to invest their time;
* this is not a performance tracking tool but it is a tool to help understand the overall health of the team and cluster.

<br>



# Procedure


We offer several options for conducting TMM depending on the context. All of them involve the entire team, regardless of roles.


**Team meeting with TMM cards in Miro**. The team votes synchronously for the level of each card on the miro-board. Also we have a game format in the form of a quest by levels, where the team gains experience in the piggy bank depending on the level of practice.


**Team meeting for filling out a Google spreadsheet**. Classic sequential discussion of cards with the team.


**Asynchronous survey with subsequent discussion**. Asynchronous filling out a Google form, and then discussing the cards together with the team, for which there is a large spread in the ratings.


Each of the formats takes from 2 to 4 hours if it is held for the first time. It is important to vote for each of the cards, a round of joint discussion when the assessment diverges, and a revote. As you go through, questions for discussion and action points will arise, which are put aside by the facilitator. At the end of the meeting, it is **important to prioritize the identified gaps** and select 3-4 focuses for the quarter. The results must be saved in the team space so that they can be returned to later.


**TMM is held three times a year**.


We recommend the first format for the first acquaintance with the tool. In the next two quarters, check the level of only those points that the teams took up or pumped up along the way â€” this will take one retrospective. At the end of the year, you can launch an asynchronous survey to get an updated overall picture.


> **IMPORTANT**
>
> How TMM is definitely not conducted: agile coach or tech lead fills in the points for the team, while the participants have not heard anything about this tool.


# Results


The TMM is passed, the levels are determined, and you want to avoid a situation where the results are sent to the box. The algorithm can be as follows:


* at the end of the exercise, select the completed items in two categories:
    * the weakest by levels (for example, all cards with level zero);
    * the most interesting for boosting.
* vote and determine the top 4 â€” your focuses for the quarter, until the next TMM check;
* gather an initiative group headed by the tech lead of the team or borrow one retrospective:
    * come up with ideas that will help raise the level (the answer is often in the card itself);
    * draw up a roadmap for initiatives for the top 4 (or further);
    * raise tasks for initiatives in the team Jira, and they can also be put into the team backlog and distributed across sprints.
* you can review and change priorities, as well as track progress during the retro at the end of each sprint to make the process more systematic.

<br>



If you do not have ideas on how to raise your level, come with a request to SMEs of each area and the PMO department â€” let's storm together! ðŸ˜ƒ




